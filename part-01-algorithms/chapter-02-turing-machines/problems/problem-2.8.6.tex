\
\subsection*{Problem 2.8.6}
\addcontentsline{toc}{subsection}{Problem 2.8.6}

\paragraph{Statement.}
Give another proof of Theorem 2.1 by presenting the \(k\) strings not next to each other, but on top of each other. Analyze the efficiency of your simulation and compare with the proof of Theorem 2.1. (A single symbol of the simulating machine will encode \(k\) symbols of the simulated one. Naturally, the cursors will be all over the place.)

\paragraph{Solution.}
Let \(M\) be a \gls{multitapetm} with \gls{tapealphabet} \(\Gamma\) and running time \(t(n)\) on inputs of length \(n\).
We construct a \gls{singletapetm} \(M'\) that simulates \(M\) using a \emph{stacked} multi-\gls{track} encoding, giving an alternative proof of Theorem~2.1.

\paragraph{Stacked encoding.}
Fix \(k\) tracks.
The tape of \(M'\) represents, at each position \(i\ge 0\), a \(k\)-tuple \((a_1,\dots,a_k)\in \Gamma^k\),
where \(a_j\) is the symbol currently stored in cell \(i\) of tape \(j\) of \(M\).
To represent head positions, \(M'\) uses a marked copy \(\widehat{\Gamma}=\{\widehat{a}:a\in\Gamma\}\):
in each track, exactly one cell carries a marked symbol \(\widehat{a}\), indicating the head position of that simulated tape.
Thus the alphabet of \(M'\) is a constant-size expansion of \(\Gamma^k\) (since \(k\) is fixed), and one symbol of \(M'\) encodes \(k\) symbols of \(M\) as required.

\paragraph{Simulating one step.}
Suppose \(M\) is in some \gls{configuration} \(C\).
To simulate one transition of \(M\) from \(C\), \(M'\) must:
\begin{enumerate}[label=(\roman*)]
  \item determine the \(k\) scanned symbols (the marked symbols, one per track),
  \item apply \(M\)'s transition function in its finite control to obtain the \(k\) writes and head moves,
  \item update the stacked tape to reflect these writes and moves.
\end{enumerate}

Because the \(k\) head markers may be at unrelated positions, \(M'\) locates them by sweeping across the active region.
Let \(L\) be the maximum tape index visited by any head of \(M\) up to the current simulated step.
Under the stacked encoding, all information needed to describe \(C\) lies in positions \(0,1,\dots,L\) of \(M'\)'s tape.

\emph{Pass 1 (gather).}
Starting at the left end, \(M'\) sweeps right from position \(0\) to position \(L\), recording in its state the \(k\) marked symbols it encounters (one per track).
Since \(k\) is constant, this requires only constant additional finite-control information.
At the end of the sweep, \(M'\) knows the \(k\)-tuple of scanned symbols and therefore knows which transition of \(M\) to simulate.

\emph{Pass 2 (update).}
\(M'\) sweeps back across \(0..L\), rewriting the marked cells with the new symbols and moving each mark one cell left/right/stay as prescribed.
A move changes only a constant neighborhood around a mark, so each simulated step can be implemented with \(O(1)\) full sweeps of length \(O(L)\).
Therefore one step of \(M\) costs \(O(L)\) steps of \(M'\).

\paragraph{Time bound.}
After \(r\) simulated steps, each head of \(M\) has moved at most \(r\) times, so \(L=O(n+r)\).
Thus simulating step \(r\) costs \(O(n+r)\) time, and the total time to simulate \(t(n)\) steps is
\begin{align*}
\sum_{r=1}^{t(n)} O(n+r)
&= O\!\left(t(n)\,n + \sum_{r=1}^{t(n)} r\right)
= O\!\left(t(n)\,n + t(n)^2\right).
\end{align*}
In particular, when \(t(n)\ge n\), this is \(O(t(n)^2)\), the standard quadratic slowdown.

\paragraph{Comparison with the ``side-by-side'' encoding.}
In the standard proof of Theorem~2.1, the \(k\) simulated tapes are laid out next to each other with delimiters, so the encoded configuration has length proportional to \(\sum_{j=1}^k \ell_j\), where \(\ell_j\) is the active length of tape \(j\).
In the stacked encoding, the configuration length is proportional to \(\max_j \ell_j\) instead.
Since
\(\max_j \ell_j \le \sum_j \ell_j \le k\max_j \ell_j\),
both encodings yield the same asymptotic \(O(t(n)^2)\) simulation time, but the stacked encoding can improve constants by avoiding an explicit factor of \(k\) in the tape length.
The tradeoff is precisely that the head markers are dispersed, so each simulated step still requires sweeping the full active region to collect the scanned symbols and then apply the updates.

\paragraph{Conclusion.}
The multi-track stacked representation yields a correct \gls{simulation} of any \gls{multitapetm} by a \gls{singletapetm} with at most quadratic time \gls{overhead}, giving an alternative proof of Theorem~2.1.
